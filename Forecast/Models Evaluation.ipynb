{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, mean_absolute_percentage_error)\n",
    "\n",
    "# Arima\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Neural Prophet\n",
    "from neuralprophet import NeuralProphet\n",
    "from neuralprophet import set_random_seed \n",
    "set_random_seed(0)  # control the random initialization of weights\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos\n",
    "df = pd.read_parquet(\"forecast_data.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a evaluar diferentes técnicas de forecasting para poder predecir los futuros retrasos de la manera más precisa posible. Para ello seleccionamos los datos correspondientes a un único aeropuerto, que será con el cual realizaremos las pruebas de modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = list(df['ORIGIN_AIRPORT'].unique())\n",
    "airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos el primer aeropuerto de la lista\n",
    "data = df[df['ORIGIN_AIRPORT'] == airports[0]]\n",
    "data = data.loc[:,['DATE', 'DELAYED_FLIGHTS']] \n",
    "\n",
    "# Cambiamos el nombre a las columnas para que vaya a corde con el modelo\n",
    "data.columns = ['ds','y']\n",
    "data['ds'] = pd.to_datetime(data['ds'],format = \"%m/%d/%Y\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable a predecir: *number of delays per airport and day*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option I. Arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo ARIMA para la predicción de series de tiempo\n",
    "ARIMA significa modelo de promedio móvil integrado autorregresivo y se especifica mediante tres parámetros de orden: (p, d, q).\n",
    "\n",
    "AR( p ) Autoregresión : un modelo de regresión que utiliza la relación dependiente entre una observación actual y las observaciones durante un período anterior Un componente auto regresivo( AR(p) ) se refiere al uso de valores pasados ​​en la ecuación de regresión para la serie de tiempo.\n",
    "\n",
    "I( d ) Integración : utiliza la diferenciación de observaciones(restando una observación de la observación en el paso de tiempo anterior) para hacer estacionaria la serie de tiempo. La diferenciación implica la resta de los valores actuales de una serie con sus valores anteriores d número de veces.<p>\n",
    "Media móvil MA( q ) : un modelo que utiliza la dependencia entre una observación y un error residual de un modelo de media móvil aplicado a observaciones retrasadas. Un componente de media móvil representa el error del modelo como una combinación de términos de error anteriores. El orden q representa el número de términos que se incluirán en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_fit = auto_arima(data['y'], start_p = 1, start_q = 1,max_p = 3, max_q = 3, m = 12,start_P = 0, \n",
    "                          seasonal = True, d = None, D = 1, trace = True,error_action ='ignore',  \n",
    "                          suppress_warnings = True,stepwise = True)          \n",
    "  \n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ajustamos el modelo al conjunto de datos\n",
    "train = data.iloc[:len(data)-31]\n",
    "test = data.iloc[len(data)-31:]\n",
    "\n",
    "arima_model = SARIMAX(train['y'],order = (1, 0, 0),seasonal_order =(2, 1, 0, 12))\n",
    "  \n",
    "result = arima_model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "start = len(train)\n",
    "end = len(train)+len(test)-1\n",
    "  \n",
    "predictions = result.predict(start, end,typ = 'levels').rename(\"Predictions\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "start = len(train)\n",
    "end = len(train)+len(test)-1\n",
    "  \n",
    "predictions = result.predict(start, end,typ = 'levels').rename(\"Predictions\")\n",
    "test['predictions'] = predictions\n",
    "\n",
    "# Prediction vs Actual values representation\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=test['ds'], y=test['y'], name = \"actual\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=test['ds'], y=test['predictions'], name = \"predictions\",line_color = px.colors.qualitative.Vivid[3]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ARIMA Model. December predictions vs. Actual values\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    #color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "    hovermode=\"x unified\",\n",
    "       \n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MSE value\n",
    "performance_arima_MSE = mean_squared_error(test['y'],test['predictions'])\n",
    "print(f'The MSE for the baseline model is {performance_arima_MSE}')\n",
    "\n",
    "# Check the MAE value\n",
    "performance_arima_MAE = mean_absolute_error(test['y'],test['predictions'])\n",
    "print(f'The MAE for the baseline model is {performance_arima_MAE}')\n",
    "\n",
    "# Check the MAPE value\n",
    "performance_arima_MAPE = mean_absolute_percentage_error(test['y'],test['predictions'])\n",
    "print(f'The MAPE for the baseline model is {performance_arima_MAPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones futuras. Vamos a estimar los retrasos futuros correspondientes a enero 2016\n",
    "model = SARIMAX(data['y'], order = (1, 0, 0),seasonal_order =(2, 1, 0, 12))\n",
    "arima_result = model.fit()\n",
    "  \n",
    "forecast = arima_result.predict(start = len(data),end = (len(data)-1) + 31,typ = 'levels').rename('Forecast')\n",
    "\n",
    "jan_2016 = pd.DataFrame()\n",
    "jan_2016['ds'] = [datetime(2016,1,1) + timedelta(days=d) for d in range((datetime(2016,1,31) - datetime(2016,1,1)).days + 1)] \n",
    "jan_2016['predictions'] = list(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast representation\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data['ds'], y=data['y'], name = \"Year 2015\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=jan_2016['ds'], y=jan_2016['predictions'], name = \"Jan 2016 forecast\",line_color = px.colors.qualitative.Vivid[3]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ARIMA Model. January 2016 predictions\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    hovermode=\"x unified\",\n",
    "       \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por último vamos a representar los datos de enero de 2015 con los de 2016.\n",
    "# Para poder comparar ambos resultados cambiamos el año de nuestros datos del 2015 al 2016 y representamos\n",
    "jan_2015 = data.iloc[0:31,:]\n",
    "jan_2015['ds'] = jan_2016['ds']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=jan_2015['ds'], y=jan_2015['y'], name = \"Jan 2015\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=jan_2016['ds'], y=jan_2016['predictions'], name = \"Jan 2016 forecast\",line_color = px.colors.qualitative.Vivid[3]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"ARIMA Model. January 2016 predictions\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    hovermode=\"x unified\",\n",
    "       \n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the MSE value\n",
    "# performance_arima_jan_MSE = mean_squared_error(jan_2015['y'],jan_2016['predictions'])\n",
    "# print(f'The MSE for the baseline model is {performance_arima_jan_MSE}')\n",
    "\n",
    "# # Check the MAE value\n",
    "# performance_arima_jan_MAE = mean_absolute_error(jan_2015['y'],jan_2016['predictions'])\n",
    "# print(f'The MAE for the baseline model is {performance_arima_jan_MAE}')\n",
    "\n",
    "# # Check the MAPE value\n",
    "# performance_arima__jan_MAPE = mean_absolute_percentage_error(jan_2015['y'],jan_2016['predictions'])\n",
    "# print(f'The MAPE for the baseline model is {performance_arima__jan_MAPE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model variables explained in: https://neuralprophet.com/code/forecaster.html\n",
    "\n",
    "Quick start guide: https://neuralprophet.com/quickstart.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "# Vamos a predecir el mes de diciembre\n",
    "train_end_date = '2015-11-30'\n",
    "\n",
    "train = data[data['ds'] <= train_end_date]\n",
    "test  = data[data['ds'] >  train_end_date]\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = NeuralProphet()\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the time range for the forecast\n",
    "future_baseline = model.make_future_dataframe(train,periods = 31)\n",
    "\n",
    "# Make prediction\n",
    "forecast_baseline = model.predict(future_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forecast dataframe does not include the actual values so we need to merge the forecast dataframe with the test dataframe to compare the actual values with the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge actual and predicted values\n",
    "performance_baseline = pd.merge(test,forecast_baseline[['ds','residual1','yhat1','trend','season_weekly']][-31:],on='ds')\n",
    "\n",
    "# Check the MSE value\n",
    "performance_baseline_MSE = mean_squared_error(performance_baseline['y'],performance_baseline['yhat1'])\n",
    "print(f'The MSE for the baseline model is {performance_baseline_MSE}')\n",
    "\n",
    "# Check the MAE value\n",
    "performance_baseline_MAE = mean_absolute_error(performance_baseline['y'],performance_baseline['yhat1'])\n",
    "print(f'The MAE for the baseline model is {performance_baseline_MAE}')\n",
    "\n",
    "# Check the MAPE value\n",
    "performance_baseline_MAPE = mean_absolute_percentage_error(performance_baseline['y'],performance_baseline['yhat1'])\n",
    "print(f'The MAPE for the baseline model is {performance_baseline_MAPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual values representation\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=performance_baseline['ds'], y=performance_baseline['y'], name = \"actual\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=performance_baseline['ds'], y=performance_baseline['yhat1'], name = \"predictions\",line_color = px.colors.qualitative.Vivid[3]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Baseline Model. December predictions vs. Actual values\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    #color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "    hovermode=\"x unified\",\n",
    "       \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representación de los datos\n",
    "fig = px.line(data, x=\"ds\", y=\"y\", labels={'ds':'Date', 'y':'Number of delays'},\n",
    "              title = \"Evolution of delayed flights per day\",color_discrete_sequence=px.colors.qualitative.Vivid, template=\"plotly_dark\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekly seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame()\n",
    "aux[\"DELAYED_FLIGHTS\"] = data.groupby(data['ds'].dt.day_name())[\"y\"].sum()\n",
    "#data[\"Vuelos Retrasados\"] = data[data[\"ARRIVAL_DELAY\"]>0].groupby(data['DATE'].dt.day_name())[\"FLIGHT_NUMBER\"].count()\n",
    "aux = aux.reindex(index = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "aux = aux.reset_index(level=0, drop=False)\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representación de los datos\n",
    "fig = px.line(aux, x=\"ds\", y=\"DELAYED_FLIGHTS\", labels={'ds':'Date', 'DELAYED_FLIGHTS':'Number of delays'},\n",
    "              title = \"Delayed flights per Week day\",color_discrete_sequence=px.colors.qualitative.Vivid, template=\"plotly_dark\")\n",
    "\n",
    "#fig.update_traces({\"line\":{\"color\":\"steelblue\", 'dash':'dash'}})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame()\n",
    "aux[\"DELAYED_FLIGHTS\"] = data.groupby(data['ds'].dt.to_period('M'))[\"y\"].sum()\n",
    "aux = aux.rename(columns={\"ds\":\"Month\"})\n",
    "aux['MONTH'] =['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "aux = aux.reset_index(level=0, drop=False)\n",
    "aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(aux, x='MONTH', y='DELAYED_FLIGHTS',\n",
    "            title = \"Delayed flights per Month\",color_discrete_sequence=px.colors.qualitative.Vivid, template=\"plotly_dark\")\n",
    "\n",
    "#fig.add_trace(px.line(aux, x='MONTH', y='DELAYED_FLIGHTS'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No añadimos yearly porque solo tenemos datos de un año ni tampoco daily porque nuestro dataset está organizado por días\n",
    "model_season = NeuralProphet(weekly_seasonality = True)\n",
    "\n",
    "# Fit the model on the training dataset\n",
    "model_season.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the time range for the forecast\n",
    "future_season = model_season.make_future_dataframe(train,periods = 31)\n",
    "\n",
    "# Make prediction\n",
    "forecast_season = model_season.predict(future_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge actual and predicted values\n",
    "performance_season = pd.merge(test,forecast_season[['ds','residual1','yhat1','trend','season_weekly']][-31:],on='ds')\n",
    "\n",
    "# Check the MSE value\n",
    "performance_season_MSE = mean_squared_error(performance_season['y'],performance_season['yhat1'])\n",
    "print(f'The MSE for the baseline model is {performance_season_MSE}')\n",
    "\n",
    "# Check the MAE value\n",
    "performance_season_MAE = mean_absolute_error(performance_season['y'],performance_season['yhat1'])\n",
    "print(f'The MAE for the baseline model is {performance_season_MAE}')\n",
    "\n",
    "# Check the MAPE value\n",
    "performance_season_MAPE = mean_absolute_percentage_error(performance_season['y'],performance_season['yhat1'])\n",
    "print(f'The MAPE for the baseline model is {performance_season_MAPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual values representation\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=performance_season['ds'], y=performance_season['y'], name = \"actual\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=performance_season['ds'], y=performance_season['yhat1'], name = \"predictions\",line_color = px.colors.qualitative.Vivid[3]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Model with seasonality. December predictions vs. Actual values\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    hovermode=\"x unified\",\n",
    "       \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunned Model. Seasonality & holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tunned = NeuralProphet(weekly_seasonality = True)\n",
    "model_tunned.add_country_holidays(country_name='US')\n",
    "model_tunned.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the time range for the forecast\n",
    "future_tunned = model_tunned.make_future_dataframe(train,periods = 31)\n",
    "\n",
    "# Make prediction\n",
    "forecast_tunned = model_tunned.predict(future_tunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge actual and predicted values\n",
    "performance_tunned = pd.merge(test,forecast_tunned[['ds','residual1','yhat1','trend','season_weekly']][-31:],on='ds')\n",
    "\n",
    "# Check the MSE value\n",
    "performance_tunned_MSE = mean_squared_error(performance_tunned['y'],performance_tunned['yhat1'])\n",
    "print(f'The MSE for the baseline model is {performance_tunned_MSE}')\n",
    "\n",
    "# Check the MAE value\n",
    "performance_tunned_MAE = mean_absolute_error(performance_tunned['y'],performance_tunned['yhat1'])\n",
    "print(f'The MAE for the baseline model is {performance_tunned_MAE}')\n",
    "\n",
    "# Check the MAPE value\n",
    "performance_tunned_MAPE = mean_absolute_percentage_error(performance_tunned['y'],performance_tunned['yhat1'])\n",
    "print(f'The MAPE for the baseline model is {performance_tunned_MAPE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual values representation\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=performance_tunned['ds'], y=performance_tunned['y'], name = \"actual\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=performance_tunned['ds'], y=performance_tunned['yhat1'], name = \"predictions\",line_color = px.colors.qualitative.Vivid[3]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Model Tunned. December predictions vs. Actual values\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    hovermode=\"x unified\",     \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunned II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tunned_II = NeuralProphet(   \n",
    "    growth=\"off\",              # no apparent trend\n",
    "    yearly_seasonality=False,  # not enough data\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,   # not hourly data\n",
    "    seasonality_reg=0,         # modulates the strength of the seasinality model --> fit larger seasonality fluctuations\n",
    "    loss_func=\"Huber\",         # Loss function that is less sensitive to outliers in data than the squared error loss.\n",
    "    normalize=\"auto\",          # Type of normalization ('minmax', 'standardize', 'soft', 'off')\n",
    ")\n",
    "model_tunned_II.add_country_holidays(country_name='US')\n",
    "model_tunned_II.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the time range for the forecast\n",
    "future_tunned_II = model_tunned_II.make_future_dataframe(train,periods = 31)\n",
    "\n",
    "# Make prediction\n",
    "forecast_tunned_II = model_tunned_II.predict(future_tunned_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge actual and predicted values\n",
    "performance_tunned_II = pd.merge(test,forecast_tunned_II[['ds','residual1','yhat1','trend','season_weekly']][-31:],on='ds')\n",
    "\n",
    "# Check the MSE value\n",
    "performance_tunned_MSE_II = mean_squared_error(performance_tunned_II['y'],performance_tunned_II['yhat1'])\n",
    "print(f'The MSE for the baseline model is {performance_tunned_MSE_II}')\n",
    "\n",
    "# Check the MAE value\n",
    "performance_tunned_MAE_II = mean_absolute_error(performance_tunned_II['y'],performance_tunned_II['yhat1'])\n",
    "print(f'The MAE for the baseline model is {performance_tunned_MAE_II}')\n",
    "\n",
    "# Check the MAPE value\n",
    "performance_tunned_MAPE_II = mean_absolute_percentage_error(performance_tunned_II['y'],performance_tunned_II['yhat1'])\n",
    "print(f'The MAPE for the baseline model is {performance_tunned_MAPE_II}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual values representation\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=performance_tunned_II['ds'], y=performance_tunned_II['y'], name = \"actual\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=performance_tunned_II['ds'], y=performance_tunned_II['yhat1'], name = \"predictions\",line_color = px.colors.qualitative.Vivid[3]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Model Tunned II. December predictions vs. Actual values\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    hovermode=\"x unified\",     \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representación de los dos modelos\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=performance_baseline['ds'], y=performance_baseline['y'], name = \"actual\", line_color = px.colors.qualitative.Vivid[1]))\n",
    "fig.add_trace(go.Scatter(x=performance_baseline['ds'], y=performance_baseline['yhat1'], name = \"baseline\", line_color = px.colors.qualitative.Vivid[5]))\n",
    "fig.add_trace(go.Scatter(x=performance_season['ds'], y=performance_season['yhat1'], name = \"season\",line_color = px.colors.qualitative.Vivid[3],mode='markers'))\n",
    "fig.add_trace(go.Scatter(x=performance_season['ds'], y=performance_tunned['yhat1'], name = \"tunned\",line_color = px.colors.qualitative.Vivid[2],mode='lines+markers'))\n",
    "fig.add_trace(go.Scatter(x=performance_season['ds'], y=performance_tunned_II['yhat1'], name = \"tunned II\",line_color = px.colors.qualitative.Vivid[4]))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Models Comparison\",\n",
    "    xaxis_title=\"Dates\",\n",
    "    yaxis_title=\"Number of delays\",\n",
    "    legend_title=\"Leyend\",\n",
    "    template=\"plotly_dark\",\n",
    "    hovermode=\"x unified\",       \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chosen model: ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d26686cbc231e22e120aec757ce4577686eae967762a57e26e2bb7fceaa36b42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
