{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos y eliminamos las filas duplicadas. Un mismo vuelo no puede retrasarse en el mismo momento del tiempo más de una vez\n",
    "df = pd.read_csv(\"../Data/flights.csv\")\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arreglo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ORIGIN_AIRPORT'] = df['ORIGIN_AIRPORT'].astype(str)\n",
    "df['DESTINATION_AIRPORT'] = df['DESTINATION_AIRPORT'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una serie de códigos de aeropuertos de origen y destino que no corresponden con el IATA_CODE asociado al aeropuerto si no que aparece un id numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aeropuertos origen: \"+ str(len(df[df['ORIGIN_AIRPORT'].str.isdigit()])))\n",
    "print(\"Aeropuertos destino: \"+ str(len(df[df['DESTINATION_AIRPORT'].str.isdigit()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para corregir esto hacemos uso del archivo airports_dict, el cual genera un diccionario en el que se asocian las claves de aeropuerto numéricas a un código str como el que tenemos en el resto de casos en función de las rutas de los vuelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el diccionario\n",
    "with open('dict_airport.json', 'rb') as fp:\n",
    "    dict_airport = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dos columnas auxiliares para reemplazar el código numérico por el codigo str de aeropuerto correspondiente\n",
    "df['CODE_ORI'] = df['ORIGIN_AIRPORT']\n",
    "df['CODE_ORI'] = df['CODE_ORI'].map(dict_airport)\n",
    "\n",
    "df['CODE_DEST'] = df['ORIGIN_AIRPORT']\n",
    "df['CODE_DEST'] = df['DESTINATION_AIRPORT'].map(dict_airport)\n",
    "\n",
    "# Sustituimos\n",
    "df['CODE_ORI'] = df['CODE_ORI'].fillna(df['ORIGIN_AIRPORT'])\n",
    "df['ORIGIN_AIRPORT'] = df['CODE_ORI']\n",
    "\n",
    "df['CODE_DEST'] = df['CODE_DEST'].fillna(df['DESTINATION_AIRPORT'])\n",
    "df['DESTINATION_AIRPORT'] = df['CODE_DEST']\n",
    "\n",
    "df = df.drop(['CODE_ORI','CODE_DEST'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos\n",
    "print(\"Aeropuertos origen: \"+ str(len(df[df['ORIGIN_AIRPORT'].str.isdigit()])))\n",
    "print(\"Aeropuertos destino: \"+ str(len(df[df['DESTINATION_AIRPORT'].str.isdigit()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** vemos que hay una serie de índices que el algoritmos no consigue emparejar con un aeropuerto. No obstante, estos datos no corresponden con una muestra representativa de los datos (poco volumen) por lo que los eliminamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['ORIGIN_AIRPORT'].str.isdigit()].index)\n",
    "df = df.drop(df[df['DESTINATION_AIRPORT'].str.isdigit()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos parte II\n",
    "print(\"Aeropuertos origen: \"+ str(len(df[df['ORIGIN_AIRPORT'].str.isdigit()])))\n",
    "print(\"Aeropuertos destino: \"+ str(len(df[df['DESTINATION_AIRPORT'].str.isdigit()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas que se pueden eliminar:\n",
    "- TAIL NUMBER: representa un ID de avión único por lo que no corresponde con una variable representativa para el análisis por lo que la eliminamos\n",
    "\n",
    "### Debatir:\n",
    "Nos importan..?\n",
    "- SCHEDULED_DEPARTURE: yo diría que no, si llega en hora = OK!\n",
    "- DEPARTURE_TIME: es interesante analizar los retrasos por tramo horario? - SI\n",
    "- DEPARTURE_DELAY: yo diría que no, si sale tarde pero llega en hora = OK! - SI\n",
    "- ARRIVAL_TIME: yo diría que no, solo me interesa si el vuelo llega tarde, no? - SI\n",
    "- SCHEDULED_TIME: no se a que se refiere  \n",
    "- SCHEDULED_ARRIVAL: solo nos interesa saber si se retrasa o no, no la previsión\n",
    "- TAXI_IN\n",
    "- TAXI_OUT\n",
    "- WHEELS_OFF\n",
    "- WHEELS_ON\n",
    "- AIR_TIME\n",
    "- FLIGHT_NUMBER - SI\n",
    "- DESTINATION_AIRPORT - DUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos tail number porque es un identificador de avión (no vuelo) único\n",
    "df = df.drop(\"TAIL_NUMBER\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos el resto de variables que no usaremos para nuestro análisis\n",
    "df = df.drop([\"SCHEDULED_DEPARTURE\", \"SCHEDULED_TIME\", \"SCHEDULED_ARRIVAL\",\n",
    "             \"TAXI_IN\", \"TAXI_OUT\", \"WHEELS_OFF\", \"WHEELS_ON\", \"AIR_TIME\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un error de formato con la variable flight number, que es un indicador del vuelo y por lo tanto una variable categórica. Lo mismo ocurre con Cancelled y Diverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos el FlightNum, Cancelled and Diverted como variables categóricas\n",
    "df['FLIGHT_NUMBER']=df['FLIGHT_NUMBER'].astype(object) \n",
    "df['CANCELLED']=df['CANCELLED'].astype(object) \n",
    "df['DIVERTED']=df['DIVERTED'].astype(object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos las columnas Year, Month y Day of Month como una única variable fecha\n",
    "# Formato por defecto mes/dia/año para que to_datetime funcione correctamente\n",
    "df[\"DATE\"]  = df['MONTH'].astype(str) +'/'+ df['DAY'].astype(str) +'/' + df['YEAR'].astype(str)\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nos interesa en algún momento podríamos añadir las horas también "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos las columnas year, month y day\n",
    "df = df.drop([\"YEAR\",\"MONTH\", \"DAY\"],axis=1)\n",
    "\n",
    "# También podemos eliminar la columna DAY_OF_WEEK ya que podemos obtenerla\n",
    "df = df.drop(\"DAY_OF_WEEK\",axis=1)\n",
    "print(f\"Ejemplo: obtener dia de la semana de la fecha {df['DATE'].iloc[0]} --> {df['DATE'].iloc[0].day_name()} (dia {df['DATE'].iloc[0].dayofweek})\")\n",
    "\n",
    "# NOTA: hay que tener en cuenta que dayofweek empieza a contar en 0 = lunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos el orden de las columnas, para que DATE sea la primera\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hablar formato tiempos: \n",
    "    SCHEDULED_DEPARTURE, DEPARTURE_TIME, SCHEDULED_TIME\n",
    "    SCHEDULED_ARRIVAL, ARRIVAL_TIME (se podrían eliminar dado que nos sirven para sacar arrival delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debatir:\n",
    "\n",
    "Las variables SCHEDULED_DEPARTURE, DEPARTURE_TIME, DEPARTURE_DELAY, ARRIVAL_TIME y SCHEDULED_ARRIVAL nos ayudan a saber si un vuelo se ha retrasado o no, pero una vez aue sabemos esto no tienen  valor en sí mismas por lo que las podemos eliminar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos de vuelo:\n",
    "1. On time/ arrived earlier --> arrival_delay <=0\n",
    "2. Delayed   --> arrival_delay > 0\n",
    "3. Diverted  --> diverted == 1\n",
    "4. Cancelled --> cancelled == 1\n",
    "\n",
    "##### Razones por las que se retrasa un vuelo:\n",
    "- AIR_SYSTEM_DELAY     \n",
    "- SECURITY_DELAY       \n",
    "- AIRLINE_DELAY        \n",
    "- LATE_AIRCRAFT_DELAY \n",
    "- WEATHER_DELAY       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vamos a examinar ahora los valores nulos\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables CANCELLATION_REASON, AIR_SYSTEM_DELAY, SECURITY_DELAY, AIRLINE_DELAY, LATE_AIRCRAFT_DELAY,WEATHER_DELAY presentan una gran cantidad de valores nulos. No obstante, todas estas variables se relacionan con vuelos cancelados o retrasados por lo que tiene sentido que sean valores nulos para aquellos vuelos que no se hayan cancelado ni retrasado. Vamos a analizar estas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelled = df[df['CANCELLED'] == 1]\n",
    "cancelled.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como en este caso no existen valores nulos para la columna CANCELLATION_REASON. No obstante, nuestro análisis consiste en prededcir el retraso de vuelos por lo que no necesitamos la info de vuelos cancelados/ redirigidos así que eliminamos dichos registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los cancelados\n",
    "df = df[df['CANCELLED'] == 0]\n",
    "\n",
    "#Eliminamos los redirigidos\n",
    "df = df[df['DIVERTED'] == 0]\n",
    "\n",
    "df = df.drop([\"DIVERTED\",\"CANCELLED\", \"CANCELLATION_REASON\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos solo con los vuelos que llegan antes de lo previsto, en hora o con retraso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos ahora el análisis de los valores nulos relacionados con los vuelos retrasados.\n",
    "\n",
    "**NOTA**: consideramos que un vuelo se retrasa si llega pasada la hora prevista, independientemente de si ha tenido retraso en la hora de salida o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed = df[df['ARRIVAL_DELAY'] > 0]\n",
    "delayed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si considerabamos todos los vuelos teníamos 1283118 registros con valor nulo en las variables DELAY, cuando filtramos por vuelos retrasados tenemos 275025.\n",
    "Vamos a analizar primero los valores nulos de aquellos vuelos que se han retrasado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed = delayed[['AIR_SYSTEM_DELAY', 'SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']]\n",
    "delayed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos todas las filas que tengan NaN en todas las columnas\n",
    "nulls = delayed.loc[(delayed['AIR_SYSTEM_DELAY'].isnull() == True) & (delayed['SECURITY_DELAY'].isnull() == True) & (delayed['AIRLINE_DELAY'].isnull() == True) & (delayed['LATE_AIRCRAFT_DELAY'].isnull() == True) & (delayed['WEATHER_DELAY'].isnull() == True)]\n",
    "len(nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que TODOS los NaN se concentran en las mismas filas. Entendemos que en este caso el vuelo se ha retrasado por causa desconocida. Para indicar esto creamos una nueva columna 'OTHER_DELAY' en nuestro data frame cuyo valor sea igual al delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la OTHER_DELAY con los mismos datos que ARRIVAL_DELAY\n",
    "df['OTHER_DELAY'] = df['ARRIVAL_DELAY']\n",
    "\n",
    "# Como hemos visto que si una columna _DELAY es NaN el resto también, utilizamos una única columa para comparar, y asignamos a OTHER_DELAY la diferencia entre el delay a la llegada y el resto de delays\n",
    "df.loc[pd.notna(df['AIR_SYSTEM_DELAY']),'OTHER_DELAY'] = df['ARRIVAL_DELAY'] - df['AIR_SYSTEM_DELAY'] - df['SECURITY_DELAY'] - df['AIRLINE_DELAY'] -df['LATE_AIRCRAFT_DELAY'] - df['WEATHER_DELAY']\n",
    "df[45:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos OTHEY_DELAY <0 por 0 dado que estos vuelos han llegado antes de lo previsto, no han experimentado un retraso\n",
    "df.loc[df[\"OTHER_DELAY\"] < 0, \"OTHER_DELAY\"] = 0\n",
    "df[45:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early arrival flights\n",
    "early_arrival = df[df['ARRIVAL_DELAY']<=0]\n",
    "\n",
    "print(len(early_arrival))\n",
    "early_arrival.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto de valores NaN en dichas columnas corresponden a aquellos vuelos que han llegado antes de tiempo a destino, cosa que tiene sentido dado que no han experimentado ningún delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez analizado el por qué de los valores NaN presentes en el dataset parece razonable sustituir dichos valores por 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos a todos los NaNs el valor 0, ya que ahora todo el retraso de sus vuelos está plasmado en la variable OTHER_DELAY\n",
    "df = df.fillna(0)\n",
    "df[45:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fillna() sustituye los NaN de todo el dataframe por lo que es importante destacar que podemos utilizar este método dado que los únicos campos NaN del dataframe se encuentran en las variables de delay analizadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulta interesante saber si los vuelos pueden retrasarse por un único motivo o exclusivamente por uno. Vamos a investigarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos la variable WEATHER_DELAY como referencia\n",
    "weather = df.loc[(df['WEATHER_DELAY'] != df['ARRIVAL_DELAY']) & (df['WEATHER_DELAY']>0 )]\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmamos, el retraso puedes estar asociado a varios motivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECKPOINT. Datos de vuelos limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Aerolíneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a añadir la el nombre asociado a las airlines\n",
    "# Cargamos los datos\n",
    "airlines = pd.read_csv(\"../Data/airlines.csv\")\n",
    "airlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a examinar ahora los valores nulos\n",
    "airlines.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos la columna \"AIRLINE\" para poder hacer el join con la tabla de aerolineas\n",
    "airlines = airlines.rename(columns={\"IATA_CODE\": \"AIRLINE_CODE\"})\n",
    "df = df.rename(columns={\"AIRLINE\": \"AIRLINE_CODE\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambas tablas\n",
    "flights = df.merge(airlines, on='AIRLINE_CODE', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ponemos la nueva columna a continuación del código de la aerolinea\n",
    "cols = flights.columns.tolist()\n",
    "cols = cols[0:2]+cols[-1:] + cols[2:-1]\n",
    "flights = flights[cols] \n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Aeropuertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a añadir la el nombre asociado a las airlines\n",
    "# Cargamos los datos\n",
    "airports = pd.read_csv(\"../Data/airports.csv\")\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a examinar ahora los valores nulos\n",
    "airports.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falta información de 3 aeropuertos, así que la rellenaremos buscando sus datos en internet e introduciéndola manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECP_COORD = [30.3549, 85.7995]\n",
    "PBG_COORD = [44.6521, 73.4679]\n",
    "UST_COORD = [29.9544, 81.3429]\n",
    "airports.at[96,[\"LATITUDE\",\"LONGITUDE\"]]= ECP_COORD\n",
    "airports.at[234,[\"LATITUDE\",\"LONGITUDE\"]]= PBG_COORD\n",
    "airports.at[313,[\"LATITUDE\",\"LONGITUDE\"]]= UST_COORD\n",
    "airports.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos la columna COUNTRY, ya que todos los aerupuertos son de Estados Unidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.drop(\"COUNTRY\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el nombre de la columna airport, ya que trabajaremos únicamente con los códigos de los aeropuertos y con sus nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports= airports.rename(columns={\"AIRPORT\": \"AIRPORT_NAME\"})\n",
    "airports= airports.rename(columns={\"IATA_CODE\": \"AIRPORT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos dos bases de datos para hacer el join con la principal tanto para aeropuertos de llegada como de salida\n",
    "airports= airports.rename(columns={\"IATA_CODE\": \"AIRPORT\"})\n",
    "\n",
    "origin_airports = airports.add_prefix('ORIGIN_')\n",
    "destination_airports = airports.add_prefix('DESTINATION_')\n",
    "\n",
    "origin_airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos las tres tablas\n",
    "flights_origin = flights.merge(origin_airports, on='ORIGIN_AIRPORT', how='left')\n",
    "flights_complete = flights_origin.merge(destination_airports, on='DESTINATION_AIRPORT', how='left')\n",
    "flights_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flights_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los datos preprocesados, para ser utilizados en la predicción posterior\n",
    "flights_complete.to_parquet(\"flightsCleaned.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3472844a7ad831f024780a557c10180eb151bb97358fb439eb3b23af04efba3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
